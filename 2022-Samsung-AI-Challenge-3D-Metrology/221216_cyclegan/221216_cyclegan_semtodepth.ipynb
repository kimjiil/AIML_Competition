{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f71bc3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkimjiil2013\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/kji/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kji/workspace/jupyter_kji/wandb/run-20221219_105429-3gxro7b2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kimjiil2013/Samsung%20sem%20CycleGan%20221216/runs/3gxro7b2\" target=\"_blank\">ruby-snowflake-45</a></strong> to <a href=\"https://wandb.ai/kimjiil2013/Samsung%20sem%20CycleGan%20221216\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import itertools\n",
    "import cv2, PIL\n",
    "import os, glob\n",
    "import csv, platform\n",
    "\n",
    "current_os = platform.system()\n",
    "if current_os == \"Linux\":\n",
    "    _path = '/home/kji/workspace/jupyter_kji/samsumg_sem_dataset'\n",
    "    cfg = {\n",
    "        'device': \"cuda:6\",\n",
    "        \"db_path\": _path,\n",
    "        'epochs': 1000,\n",
    "        'batch_size': 128,\n",
    "        'lr': 0.0002,\n",
    "        'num_workers': 4,\n",
    "        'n_fold': 5\n",
    "    }\n",
    "elif current_os == \"Windows\":\n",
    "    _path = 'D:/git_repos/samsung_sem'\n",
    "    cfg = {\n",
    "        'device': \"cuda:0\",\n",
    "        \"db_path\": _path,\n",
    "        'epochs': 100,\n",
    "        'batch_size': 4,\n",
    "        'lr': 0.0002,\n",
    "        'num_workers': 0,\n",
    "        'n_fold': 5\n",
    "    }\n",
    "\n",
    "import wandb\n",
    "\n",
    "wandb.login(key='0322000365224d30ef0694f60237c68767290052')\n",
    "wandb.init(project=\"Samsung sem CycleGan 221216\", entity=\"kimjiil2013\")\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891c5cf3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc3f3665",
   "metadata": {},
   "outputs": [],
   "source": [
    "class resnet_block(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(resnet_block, self).__init__()\n",
    "\n",
    "        _resnet_block = [\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim, dim, kernel_size=3, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim, dim, kernel_size=3, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(dim)\n",
    "        ]\n",
    "\n",
    "        self.layer = nn.Sequential(*_resnet_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer(x) + x\n",
    "        return out\n",
    "\n",
    "class ResnetGenerator(nn.Module):\n",
    "    def __init__(self, input_ch):\n",
    "        super(ResnetGenerator, self).__init__()\n",
    "\n",
    "        self.init_layer = nn.Sequential(\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(input_ch, 16, kernel_size=7, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True))\n",
    "\n",
    "        self.donw_sampling_layer1 = nn.Sequential(\n",
    "            # down sampling\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self.donw_sampling_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True))\n",
    "\n",
    "        self.res_block = nn.Sequential(*[resnet_block(64) for i in range(3)])\n",
    "\n",
    "        self.up_samplig_layer1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1, bias=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self.up_samplig_layer2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1, bias=True),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(16, input_ch, kernel_size=7, padding=0),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.model(x)\n",
    "        out1 = self.init_layer(x)\n",
    "        out2 = self.donw_sampling_layer1(out1)\n",
    "        out3 = self.donw_sampling_layer2(out2)\n",
    "        out4 = self.res_block(out3)\n",
    "        out5 = self.up_samplig_layer1(out4)\n",
    "        out6 = self.up_samplig_layer2(out5)\n",
    "        out7 = self.output_layer(out6)\n",
    "        return out7\n",
    "\n",
    "    def set_requires_grad(self, mode):\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = mode\n",
    "\n",
    "class PatchGanDiscriminator(nn.Module):\n",
    "    def __init__(self, input_ch):\n",
    "        super(PatchGanDiscriminator, self).__init__()\n",
    "\n",
    "        model = [\n",
    "            nn.Conv2d(input_ch, 16, kernel_size=7, stride=1, padding=1, padding_mode='replicate'),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            nn.Conv2d(16, 16, kernel_size=4, stride=2, padding=1, bias=True),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(p=0.2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=4, stride=2, padding=1, bias=True),  # 1\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(p=0.2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1, bias=True),  # 2\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(p=0.2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(p=0.2),\n",
    "\n",
    "            nn.Conv2d(128, 1, kernel_size=4, stride=1, padding=1)\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def set_requires_grad(self, mode):\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = mode\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, gan_mode):\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(1.0))\n",
    "        self.register_buffer('fake_label', torch.tensor(0.0))\n",
    "        self.gan_mode = gan_mode\n",
    "\n",
    "        if gan_mode == 'lsgan':\n",
    "            self.loss = nn.MSELoss()\n",
    "        elif gan_mode == 'wgan_gp':\n",
    "            self.loss = None\n",
    "\n",
    "    def __call__(self, prediction, target_is_real):\n",
    "        if self.gan_mode == 'lsgan':\n",
    "            if target_is_real:\n",
    "                target_tensor = self.real_label  # .to(self.device)\n",
    "            else:\n",
    "                target_tensor = self.fake_label  # .to(self.device)\n",
    "\n",
    "            target_tensor = target_tensor.expand_as(prediction)\n",
    "            loss = self.loss(prediction, target_tensor)\n",
    "        elif self.gan_mode == 'wgan_gp':\n",
    "            if target_is_real:\n",
    "                loss = -prediction.mean()\n",
    "            else:\n",
    "                loss = prediction.mean()\n",
    "        return loss\n",
    "\n",
    "def _gradient_penalty(netD, real_data, fake_data, type=\"mixed\", constant=1.0, lambda_gp=10.0):\n",
    "    if lambda_gp > 0.0:\n",
    "        if type == 'real':  # either use real images, fake images, or a linear interpolation of two.\n",
    "            interpolatesv = real_data\n",
    "        elif type == 'fake':\n",
    "            interpolatesv = fake_data\n",
    "        elif type == 'mixed':\n",
    "            alpha = torch.rand(real_data.shape[0], 1, device=real_data.device)\n",
    "            alpha = alpha.expand(real_data.shape[0], real_data.nelement() // real_data.shape[0]).contiguous().view(\n",
    "                *real_data.shape)\n",
    "            interpolatesv = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "        else:\n",
    "            raise NotImplementedError('{} not implemented'.format(type))\n",
    "        interpolatesv.requires_grad_(True)\n",
    "        disc_interpolates = netD(interpolatesv)\n",
    "        gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=interpolatesv,\n",
    "                                        grad_outputs=torch.ones(disc_interpolates.size()).to(real_data.device),\n",
    "                                        create_graph=True, retain_graph=True, only_inputs=True)\n",
    "        gradients = gradients[0].view(real_data.size(0), -1)  # flat the data\n",
    "        gradient_penalty = (((gradients + 1e-16).norm(2, dim=1) - constant) ** 2).mean() * lambda_gp  # added eps\n",
    "        return gradient_penalty, gradients\n",
    "    else:\n",
    "        return 0.0, None\n",
    "\n",
    "class cycleGAN_model(nn.Module):\n",
    "    def __init__(self, input_ch=3,\n",
    "                 optim_lr=0.0002,\n",
    "                 gan_mode='lsgan',\n",
    "                 guided=False):\n",
    "        import itertools\n",
    "\n",
    "        super(cycleGAN_model, self).__init__()\n",
    "        self.gan_mode = gan_mode\n",
    "        self.guided = guided\n",
    "\n",
    "        self.Gen = nn.ModuleDict({\n",
    "            'A': ResnetGenerator(input_ch),\n",
    "            'B': ResnetGenerator(input_ch)\n",
    "        })\n",
    "\n",
    "        wandb.watch(self.Gen['A'], log='all')\n",
    "        wandb.watch(self.Gen['B'], log='all')\n",
    "\n",
    "        self.Dis = nn.ModuleDict({\n",
    "            'A': PatchGanDiscriminator(input_ch),\n",
    "            'B': PatchGanDiscriminator(input_ch)\n",
    "        })\n",
    "\n",
    "        wandb.watch(self.Dis['A'], log='all')\n",
    "        wandb.watch(self.Dis['B'], log='all')\n",
    "\n",
    "        self.optimizer = {\n",
    "            'G': torch.optim.Adam(itertools.chain(self.Gen['A'].parameters(), self.Gen['B'].parameters()), lr=optim_lr,\n",
    "                                  betas=(0.5, 0.999)),\n",
    "            'D_A': torch.optim.Adam(self.Dis['A'].parameters(), lr=optim_lr,\n",
    "                                  betas=(0.5, 0.999)),\n",
    "            'D_B': torch.optim.Adam(self.Dis['B'].parameters(), lr=optim_lr,\n",
    "                                  betas=(0.5, 0.999))\n",
    "        }\n",
    "\n",
    "        self.schedular = {\n",
    "            'G': torch.optim.lr_scheduler.LambdaLR(self.optimizer['G'], lr_lambda=lambda epoch: 0.95 ** epoch),\n",
    "            'D_A': torch.optim.lr_scheduler.LambdaLR(self.optimizer['D_A'], lr_lambda=lambda epoch: 0.95 ** epoch),\n",
    "            'D_B': torch.optim.lr_scheduler.LambdaLR(self.optimizer['D_B'], lr_lambda=lambda epoch: 0.95 ** epoch)\n",
    "        }\n",
    "\n",
    "        self.criterion = nn.ModuleDict({\n",
    "            'cycle': nn.L1Loss(),\n",
    "            'idt': nn.L1Loss(),\n",
    "            'gan': GANLoss(self.gan_mode),\n",
    "            'mse': nn.MSELoss(),\n",
    "            'guided': nn.L1Loss()\n",
    "        })\n",
    "\n",
    "        self.lambda_idt = 0.5\n",
    "        self.lambda_A = 10.0\n",
    "        self.lambda_B = 10.0\n",
    "\n",
    "    def forward(self, data_A, data_B, mode: str):\n",
    "        if mode == 'gen':\n",
    "            A_out = self.Gen['A'](data_A)\n",
    "            B_out = self.Gen['B'](data_B)\n",
    "        elif mode == 'dis':\n",
    "            A_out = self.Dis['A'](data_A)\n",
    "            B_out = self.Dis['B'](data_B)\n",
    "        else:\n",
    "            raise None\n",
    "        return A_out, B_out\n",
    "\n",
    "    def model_train_discriminator(self, real_A, real_B):\n",
    "        self.train()\n",
    "\n",
    "        fake_B, fake_A = self(real_A, real_B, 'gen')\n",
    "\n",
    "        self.set_requires_grad('dis', True)\n",
    "\n",
    "        self.optimizer['D_B'].zero_grad()\n",
    "\n",
    "        pred_real_B, pred_real_A = self(real_B, real_A, 'dis')  # netA netB\n",
    "        pred_fake_B, pred_fake_A = self(fake_B.detach(), fake_A.detach(), 'dis')\n",
    "\n",
    "        # Discriminator B update\n",
    "        loss_D_B_Real = self.criterion['gan'](pred_real_A, True)\n",
    "        loss_D_B_fake = self.criterion['gan'](pred_fake_A, False)\n",
    "\n",
    "        if self.gan_mode == 'lsgan':\n",
    "            loss_D_B = (loss_D_B_fake + loss_D_B_Real) * 0.5\n",
    "        elif self.gan_mode == 'wgan_gp':\n",
    "            gradient_penalty_B = _gradient_penalty(self.Dis['B'], real_A, fake_A.detach())\n",
    "            loss_D_B = loss_D_B_fake + loss_D_B_Real + gradient_penalty_B[0]\n",
    "\n",
    "        loss_D_B.backward()\n",
    "        self.optimizer['D_B'].step()\n",
    "\n",
    "        # Discriminator A update\n",
    "        self.optimizer['D_A'].zero_grad()\n",
    "\n",
    "        loss_D_A_Real = self.criterion['gan'](pred_real_B, True)\n",
    "        loss_D_A_fake = self.criterion['gan'](pred_fake_B, False)\n",
    "\n",
    "        if self.gan_mode == 'lsgan':\n",
    "            loss_D_A = (loss_D_A_Real + loss_D_A_fake) * 0.5\n",
    "        elif self.gan_mode == 'wgan_gp':\n",
    "            gradient_penalty_A = _gradient_penalty(self.Dis['A'], real_B, fake_B.detach())\n",
    "            loss_D_A = loss_D_A_Real + loss_D_A_fake + gradient_penalty_A[0]\n",
    "\n",
    "        loss_D_A.backward()\n",
    "        self.optimizer['D_A'].step()\n",
    "\n",
    "        loss_dic = {'dis_a': loss_D_A.item(),\n",
    "                    'dis_b': loss_D_B.item()}\n",
    "\n",
    "        return loss_dic\n",
    "\n",
    "    def model_train_generator(self, real_A, real_B):\n",
    "        self.train()\n",
    "\n",
    "        fake_B, fake_A = self(real_A, real_B, 'gen')\n",
    "        rec_B, rec_A = self(fake_A, fake_B, 'gen')\n",
    "\n",
    "        self.set_requires_grad('dis', False)\n",
    "        self.optimizer['G'].zero_grad()\n",
    "\n",
    "        idt_A, idt_B = self(real_B, real_A, 'gen')\n",
    "\n",
    "        loss_idt_A = self.criterion['idt'](idt_A, real_B) * self.lambda_B * self.lambda_idt\n",
    "        loss_idt_B = self.criterion['idt'](idt_B, real_A) * self.lambda_A * self.lambda_idt\n",
    "\n",
    "        dis_A_fake_B, dis_B_fake_A = self(fake_B, fake_A, 'dis')  # dis_A(fake_B) / dis_B(fake_A)\n",
    "\n",
    "        loss_G_A = self.criterion['gan'](dis_A_fake_B, True)\n",
    "        loss_G_B = self.criterion['gan'](dis_B_fake_A, True)\n",
    "\n",
    "        loss_cycle_A = self.criterion['cycle'](rec_A, real_A) * self.lambda_A\n",
    "        loss_cycle_B = self.criterion['cycle'](rec_B, real_B) * self.lambda_B\n",
    "\n",
    "        # Guied Loss (paired)\n",
    "        if self.guided:\n",
    "            loss_guided_A = self.criterion['guided'](fake_B, real_B)\n",
    "            loss_guided_B = self.criterion['guided'](fake_A, real_A)\n",
    "        else:\n",
    "            loss_guided_A = 0\n",
    "            loss_guided_B = 0\n",
    "        ##########\n",
    "\n",
    "        loss_Gen = loss_G_A + loss_G_B + loss_cycle_A + loss_cycle_B + loss_idt_A + loss_idt_B + loss_guided_A + loss_guided_B\n",
    "        loss_Gen.backward()\n",
    "\n",
    "        self.optimizer['G'].step()\n",
    "\n",
    "        loss_dic = {'gen': loss_Gen.item()}\n",
    "\n",
    "        inference_image = {\n",
    "            'real_a': real_A,\n",
    "            'real_b': real_B,\n",
    "            'atob_fake': fake_B,\n",
    "            'btoa_fake': fake_A,\n",
    "            'rec_a': rec_A,\n",
    "            'rec_b': rec_B\n",
    "        }\n",
    "\n",
    "        return loss_dic, {key: self.tensortonp(inference_image[key]) for key in inference_image}\n",
    "\n",
    "    def model_valid(self, real_A, real_B):\n",
    "        self.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            fake_B, fake_A = self(real_A, real_B, 'gen')\n",
    "\n",
    "            true = (real_B * 255).type(torch.uint8).float()\n",
    "            fake_true = (fake_B * 255).type(torch.uint8).float()\n",
    "            rmse_loss = torch.sqrt(self.criterion['mse'](fake_true, true))\n",
    "\n",
    "        img_dict = {\n",
    "            'real_A': real_A,\n",
    "            'fake_B': fake_B,\n",
    "\n",
    "            'real_B': real_B,\n",
    "            'fake_A': fake_A,\n",
    "        }\n",
    "\n",
    "        return rmse_loss.item(), {key: self.tensortonp(img_dict[key]) for key in img_dict}\n",
    "\n",
    "    def tensortonp(self, tensor):\n",
    "        return (tensor.detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "\n",
    "    def set_requires_grad(self, net_type='dis', mode=True):\n",
    "        if net_type == 'gen':\n",
    "            net_dic = self.Gen\n",
    "        elif net_type == 'dis':\n",
    "            net_dic = self.Dis\n",
    "\n",
    "        for key in net_dic:\n",
    "            net_dic[key].set_requires_grad(mode)\n",
    "\n",
    "    def schedular_step(self):\n",
    "        self.schedular['G'].step()\n",
    "        self.schedular['D_A'].step()\n",
    "        self.schedular['D_B'].step()\n",
    "\n",
    "    def model_save(self, PATH):\n",
    "        temp_dict = {}\n",
    "        key_list = [key for key in self.__dict__.keys() if not '_' in key[0]]\n",
    "        key_list.extend([key for key in self.__dict__['_modules'].keys()])\n",
    "\n",
    "        for key in key_list:\n",
    "            if hasattr(self, key):\n",
    "                value = getattr(self, key)\n",
    "                if isinstance(value, dict):\n",
    "                    if not key in temp_dict:\n",
    "                        temp_dict[key] = {}\n",
    "                    for sub_key in value.keys():\n",
    "                        if not sub_key in temp_dict[key]:\n",
    "                            temp_dict[key][sub_key] = value[sub_key].state_dict()\n",
    "                elif isinstance(value, nn.ModuleDict):\n",
    "                    if not key in temp_dict:\n",
    "                        temp_dict[key] = value.state_dict()\n",
    "                else:\n",
    "                    if not key in temp_dict:\n",
    "                        temp_dict[key] = value\n",
    "\n",
    "        torch.save(temp_dict, PATH)\n",
    "\n",
    "    def model_load(self, PATH, device):\n",
    "        state_dict = torch.load(PATH, map_location=device)\n",
    "\n",
    "        for cls_key in state_dict.keys():\n",
    "            if hasattr(self, cls_key):\n",
    "                value = getattr(self, cls_key)\n",
    "                if isinstance(value, dict):\n",
    "                    for sub_key in value.keys():\n",
    "                        value[sub_key].load_state_dict(state_dict[cls_key][sub_key])\n",
    "                elif isinstance(value, nn.ModuleDict):\n",
    "                    value.load_state_dict(state_dict[cls_key])\n",
    "                else:\n",
    "                    setattr(self, cls_key, state_dict[cls_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba34e7b7",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52cbc3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_list(abs_path):\n",
    "    # abs_path = '/home/kji/workspace/jupyter_kji/samsumg_sem_dataset'\n",
    "\n",
    "    # Dataset path\n",
    "    sim_depth_path = os.path.join(abs_path, 'simulation_data/Depth')\n",
    "    sim_sem_path = os.path.join(abs_path, 'simulation_data/SEM')\n",
    "\n",
    "    train_path = os.path.join(abs_path, 'train')\n",
    "\n",
    "    # only Test\n",
    "    test_path = os.path.join(abs_path, 'test/SEM')\n",
    "\n",
    "    sim_depth_img_path_dic = dict()\n",
    "    for case in os.listdir(sim_depth_path):\n",
    "        if not case in sim_depth_img_path_dic:\n",
    "            sim_depth_img_path_dic[case] = []\n",
    "        for folder in os.listdir(os.path.join(sim_depth_path, case)):\n",
    "            img_list = glob.glob(os.path.join(sim_depth_path, case, folder, '*.png'))\n",
    "            for img in img_list:\n",
    "                sim_depth_img_path_dic[case].append(img)\n",
    "                sim_depth_img_path_dic[case].append(img)\n",
    "\n",
    "    sim_sem_img_path_dic = dict()\n",
    "    for case in os.listdir(sim_sem_path):\n",
    "        if not case in sim_sem_img_path_dic:\n",
    "            sim_sem_img_path_dic[case] = []\n",
    "        for folder in os.listdir(os.path.join(sim_sem_path, case)):\n",
    "            img_list = glob.glob(os.path.join(sim_sem_path, case, folder, '*.png'))\n",
    "            sim_sem_img_path_dic[case].extend(img_list)\n",
    "\n",
    "    train_avg_depth = dict()\n",
    "    with open(os.path.join(train_path, \"average_depth.csv\"), 'r') as csvfile:\n",
    "        temp = csv.reader(csvfile)\n",
    "        for idx, line in enumerate(temp):\n",
    "            if idx > 0:\n",
    "                depth_key, site_key = line[0].split('_site')\n",
    "                depth_key = depth_key.replace(\"d\", \"D\")\n",
    "                site_key = \"site\" + site_key\n",
    "                if not depth_key in train_avg_depth:\n",
    "                    train_avg_depth[depth_key] = dict()\n",
    "\n",
    "                train_avg_depth[depth_key][site_key] = float(line[1])\n",
    "\n",
    "    train_img_path_dic = dict()\n",
    "    for depth in os.listdir(os.path.join(train_path, \"SEM\")):\n",
    "        if not depth in train_img_path_dic:\n",
    "            train_img_path_dic[depth] = []\n",
    "        for site in os.listdir(os.path.join(train_path, \"SEM\", depth)):\n",
    "            img_list = glob.glob(os.path.join(train_path, \"SEM\", depth, site, \"*.png\"))\n",
    "            train_img_path_dic[depth].extend([[temp_img, train_avg_depth[depth][site]] for temp_img in img_list])\n",
    "\n",
    "    test_img_path_list = glob.glob(os.path.join(test_path, \"*.png\"))\n",
    "\n",
    "    result_dic = dict()\n",
    "    result_dic['sim'] = dict()\n",
    "    result_dic['sim']['sem'] = sim_sem_img_path_dic\n",
    "    result_dic['sim']['depth'] = sim_depth_img_path_dic\n",
    "    result_dic['train'] = train_img_path_dic\n",
    "    result_dic['test'] = np.array(test_img_path_list)\n",
    "    result_dic['train_avg_depth'] = train_avg_depth\n",
    "\n",
    "    return result_dic\n",
    "\n",
    "result_dic = get_img_list(cfg['db_path'])\n",
    "\n",
    "## create k-fold\n",
    "def K_fold(k, result_dic):\n",
    "    # case1 case2 case3 case4\n",
    "    # sim_sem(173,304) _itr0,1 <-> sem_depth(86,652) * 2\n",
    "    def ret_chunk(path_dic):\n",
    "        case_len_list = list(map(len, [path_dic[case] for case in path_dic])) # [43326, 43326, 43326, 43326] => [ [(0,11111) (11111,22222) (22222,33333) (33333,None)]\n",
    "        def ret_slice_indices(k, size):\n",
    "            chunk_size = int(size / k)\n",
    "            _list = []\n",
    "            for i in range(k):\n",
    "                if i == k-1:\n",
    "                    _list.append(slice(i * chunk_size, None))\n",
    "                else:\n",
    "                    _list.append(slice(i * chunk_size, (i + 1) * chunk_size))\n",
    "            return _list\n",
    "\n",
    "        case_list = [path_dic[case] for case in path_dic]\n",
    "        slice_indice = list(map(ret_slice_indices, [k]*k, case_len_list))\n",
    "        chunk_list = [[c[s] for s in slice_list] for c, slice_list in zip(case_list, slice_indice)]\n",
    "\n",
    "        merge_chunk = [[] for i in range(k)]\n",
    "        for c in chunk_list:\n",
    "            for i, chunk in enumerate(c):\n",
    "                merge_chunk[i].extend(chunk)\n",
    "\n",
    "        return merge_chunk\n",
    "\n",
    "    sim_sem_chunk = ret_chunk(result_dic['sim']['sem'])\n",
    "    sem_depth_chunk = ret_chunk(result_dic['sim']['depth'])\n",
    "    train_chunk = ret_chunk(result_dic['train'])\n",
    "\n",
    "    chunk_dic = dict()\n",
    "    chunk_dic['sim_sem'] = sim_sem_chunk\n",
    "    chunk_dic['sim_depth'] = sem_depth_chunk\n",
    "    chunk_dic['train'] = train_chunk\n",
    "\n",
    "    return chunk_dic\n",
    "\n",
    "chunk_dic = K_fold(cfg['n_fold'], result_dic)\n",
    "\n",
    "class gan_dataset(Dataset):\n",
    "    def __init__(self, a_data_path, b_data_path, transform=None):\n",
    "        super(gan_dataset, self).__init__()\n",
    "        self.a_data_path = a_data_path\n",
    "        self.b_data_path = b_data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.a_size = len(a_data_path)\n",
    "        self.b_size = len(b_data_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.a_size > self.b_size:\n",
    "            a_idx = idx\n",
    "            b_idx = idx % self.b_size\n",
    "        else:\n",
    "            a_idx = idx % self.a_size\n",
    "            b_idx = idx\n",
    "        if isinstance(self.a_data_path[a_idx], str):\n",
    "            a_path = self.a_data_path[a_idx]\n",
    "        elif isinstance(self.a_data_path[a_idx], list):\n",
    "            a_path = self.a_data_path[a_idx][0]\n",
    "\n",
    "        if isinstance(self.b_data_path[b_idx], str):\n",
    "            b_path = self.b_data_path[b_idx]\n",
    "        elif isinstance(self.b_data_path[b_idx], list):\n",
    "            b_path = self.b_data_path[b_idx][0]\n",
    "\n",
    "        a_img = PIL.Image.open(a_path).convert(\"L\")\n",
    "        b_img = PIL.Image.open(b_path).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            a_img = self.transform(a_img)\n",
    "            b_img = self.transform(b_img)\n",
    "\n",
    "        a_img = (np.array(a_img) / 255.)\n",
    "        a_img = a_img.reshape(1, *a_img.shape).astype(np.float32)\n",
    "        b_img = (np.array(b_img) / 255.)\n",
    "        b_img = b_img.reshape(1, *b_img.shape).astype(np.float32)\n",
    "\n",
    "        return a_img, b_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.a_data_path), len(self.b_data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a149c6",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20860a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138644\n",
      "138644\n",
      "138644\n",
      "138644\n",
      "138640\n",
      "138644\n",
      "138644\n",
      "138644\n",
      "138644\n",
      "138640\n"
     ]
    }
   ],
   "source": [
    "horizon_transform = transforms.RandomHorizontalFlip(1.0)\n",
    "rotate_transform = transforms.RandomRotation((180, 180))\n",
    "vertical_transform = transforms.RandomVerticalFlip(1.0)\n",
    "\n",
    "transform_list = [horizon_transform, rotate_transform, vertical_transform]\n",
    "\n",
    "def kfold_dataloader(A, B, chunk_dic, cfg, transform_list):\n",
    "    dataset_list = []\n",
    "    for i in range(cfg['n_fold']):  # n_fold\n",
    "        A_train_data_list = []\n",
    "        A_valid_data_list = []\n",
    "        B_train_data_list = []\n",
    "        B_valid_data_list = []\n",
    "        for j in range(cfg['n_fold']):\n",
    "            if i == j:\n",
    "                A_valid_data_list.extend(chunk_dic[A][j])\n",
    "                B_valid_data_list.extend(chunk_dic[B][j])\n",
    "            else:\n",
    "                A_train_data_list.extend(chunk_dic[A][j])\n",
    "                B_train_data_list.extend(chunk_dic[B][j])\n",
    "\n",
    "        dataset_list.append([A_train_data_list, A_valid_data_list, B_train_data_list, B_valid_data_list])\n",
    "\n",
    "    temp = []\n",
    "\n",
    "    for dataset in dataset_list:\n",
    "        dataset_transform = []\n",
    "        train_dataset = gan_dataset(a_data_path=dataset[0],\n",
    "                                    b_data_path=dataset[2],\n",
    "                                    transform=None)\n",
    "        valid_dataset = gan_dataset(a_data_path=dataset[1],\n",
    "                                    b_data_path=dataset[3],\n",
    "                                    transform=None)\n",
    "        dataset_transform.append([train_dataset, valid_dataset])\n",
    "        print(len(train_dataset))\n",
    "        for _transform in transform_list:\n",
    "            train_dataset = gan_dataset(a_data_path=dataset[0],\n",
    "                                        b_data_path=dataset[2],\n",
    "                                        transform=_transform)\n",
    "            valid_dataset = gan_dataset(a_data_path=dataset[1],\n",
    "                                        b_data_path=dataset[3],\n",
    "                                        transform=_transform)\n",
    "            dataset_transform.append([train_dataset, valid_dataset])\n",
    "\n",
    "        train_dataset = dataset_transform[0][0] + dataset_transform[1][0] + dataset_transform[2][0] + \\\n",
    "                        dataset_transform[3][0]\n",
    "\n",
    "        valid_dataset = dataset_transform[0][1] + dataset_transform[1][1] + dataset_transform[2][1] + \\\n",
    "                        dataset_transform[3][1]\n",
    "        temp.append([train_dataset, valid_dataset])\n",
    "\n",
    "    folds_dataloader = []  # k개의 datalodaer를 저장함\n",
    "    for fold in temp:\n",
    "        train_loader = DataLoader(fold[0], batch_size=cfg['batch_size'], shuffle=True,\n",
    "                                  num_workers=cfg['num_workers'])\n",
    "        valid_loader = DataLoader(fold[1], batch_size=cfg['batch_size'], shuffle=False,\n",
    "                                  num_workers=cfg['num_workers'])\n",
    "\n",
    "        folds_dataloader.append([train_loader, valid_loader])\n",
    "\n",
    "    return folds_dataloader\n",
    "\n",
    "# create dataset - A: sim sem -> B: train sem\n",
    "folds_dataloader_simtotrain = kfold_dataloader('sim_sem', 'train', chunk_dic, cfg, transform_list)\n",
    "\n",
    "# create dataset - A: sim sem -> B: sim depth\n",
    "folds_dataloader_semtodepth = kfold_dataloader('sim_sem', 'sim_depth', chunk_dic, cfg, transform_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a67aa21",
   "metadata": {},
   "source": [
    "# Train & Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b0c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def valid(model, valid_dataloader, device):\n",
    "    rmse_list = []\n",
    "    for step_i, data_tuple in enumerate(valid_dataloader):\n",
    "        real_a = data_tuple[0].to(device, non_blocking=True)\n",
    "        real_b = data_tuple[1].to(device, non_blocking=True)\n",
    "\n",
    "        rmse_loss, img_dict = model.model_valid(real_a, real_b)\n",
    "        rmse_list.append(rmse_loss)\n",
    "        if step_i == 0:\n",
    "            img_list = [img_dict[key][0][0] for key in img_dict]\n",
    "            img_list = [wandb.Image(PIL.Image.fromarray(np.concatenate((img_list[i], img_list[i+1]), axis=-1)).convert('L'), caption=key)\n",
    "                        for i, key in enumerate(img_dict.keys()) if i % 2 == 0]\n",
    "            wandb.log({\n",
    "                \"example image\": img_list\n",
    "            })\n",
    "\n",
    "    return np.mean(rmse_list)\n",
    "\n",
    "def training(model, train_dataloader, valid_dataloader, epochs, device, fold_i, type, checkpoint_path=None):\n",
    "    best_rmse_loss = 9999\n",
    "    critic_iter = 5\n",
    "    best_epoch = 0\n",
    "\n",
    "    if checkpoint_path:\n",
    "        model.model_load(checkpoint_path, device)\n",
    "\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        loss_list = [[], [], []]\n",
    "        for step_i, data_tuple in enumerate(train_dataloader):\n",
    "            real_a = data_tuple[0].to(device, non_blocking=True)\n",
    "            real_b = data_tuple[1].to(device, non_blocking=True)\n",
    "\n",
    "            dis_loss = model.model_train_discriminator(real_a, real_b)\n",
    "            loss_list[1].append(dis_loss['dis_a'])\n",
    "            loss_list[2].append(dis_loss['dis_b'])\n",
    "            if step_i % critic_iter == 0:\n",
    "                gen_loss, img_dic = model.model_train_generator(real_a, real_b)\n",
    "                loss_list[0].append(gen_loss['gen'])\n",
    "\n",
    "                wandb.log({\n",
    "                    'Gen_step_loss': gen_loss,\n",
    "                    'Dis_A_step_loss': dis_loss['dis_a'],\n",
    "                    'Dis_B_step_loss': dis_loss['dis_b']\n",
    "                })\n",
    "\n",
    "        rmse_loss = valid(model, valid_dataloader, device)\n",
    "        print(f'epoch - {epoch}, gen loss - {gen_loss}, rmse loss - {rmse_loss}')\n",
    "        wandb.log({\n",
    "            'Gen_loss': np.mean(loss_list[0]),\n",
    "            'Dis_A_loss': np.mean(loss_list[1]),\n",
    "            'Dis_B_loss': np.mean(loss_list[2]),\n",
    "            'learning_rate': model.schedular['G'].get_lr(),\n",
    "            'rmse_loss': rmse_loss\n",
    "        })\n",
    "\n",
    "        if best_rmse_loss > rmse_loss:\n",
    "            best_rmse_loss = rmse_loss\n",
    "            model.model_save(f'./type{type}_f{fold_i}_best_model.pth')\n",
    "\n",
    "        model.schedular_step()\n",
    "    print(f'training end, best epoch - {best_epoch}, best valid rmse loss - {best_rmse_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b20dfd",
   "metadata": {},
   "source": [
    "# Simulation Sem Image to Simulation Depth Image Training #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42beec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 4333 valid 1084\n"
     ]
    }
   ],
   "source": [
    "for fold_i, data_loaders in enumerate(folds_dataloader_semtodepth):\n",
    "    print(\"train\", len(data_loaders[0]), \"valid\", len(data_loaders[1]))\n",
    "\n",
    "    model = cycleGAN_model(1, optim_lr=0.0002, gan_mode='wgan_gp', guided=False)\n",
    "    training(model=model,\n",
    "             train_dataloader=data_loaders[0],\n",
    "             valid_dataloader=data_loaders[1],\n",
    "             epochs=cfg['epochs'],\n",
    "             device=cfg['device'],\n",
    "             fold_i=fold_i,\n",
    "             type='semtodepth')\n",
    "\n",
    "    if fold_i == 0:\n",
    "        break\n",
    "        \n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d9c4b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56efec2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
