{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c680477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import itertools\n",
    "import cv2, PIL\n",
    "import os, glob\n",
    "import csv, platform\n",
    "\n",
    "current_os = platform.system()\n",
    "if current_os == \"Linux\":\n",
    "    _path = '/home/kji/workspace/jupyter_kji/samsumg_sem_dataset'\n",
    "    cfg = {\n",
    "        'device': \"cuda:6\",\n",
    "        \"db_path\": _path,\n",
    "        'epochs': 50,\n",
    "        'batch_size': 64,\n",
    "        'lr': 0.0002,\n",
    "        'num_workers': 4,\n",
    "        'n_fold': 5\n",
    "    }\n",
    "elif current_os == \"Windows\":\n",
    "    _path = 'D:/git_repos/samsung_sem'\n",
    "    cfg = {\n",
    "        'device': \"cuda:0\",\n",
    "        \"db_path\": _path,\n",
    "        'epochs': 100,\n",
    "        'batch_size': 4,\n",
    "        'lr': 0.0002,\n",
    "        'num_workers': 0,\n",
    "        'n_fold': 5\n",
    "    }\n",
    "\n",
    "import wandb\n",
    "\n",
    "project_name = \"221227_Samsung_sem\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8c4e94",
   "metadata": {},
   "source": [
    "# Cycle Gan Model,  Generator:Resnet, Discriminator:PatchGan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2307193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class resnet_block(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(resnet_block, self).__init__()\n",
    "\n",
    "        _resnet_block = [\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim, dim, kernel_size=3, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(dim, dim, kernel_size=3, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(dim)\n",
    "        ]\n",
    "\n",
    "        self.layer = nn.Sequential(*_resnet_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer(x) + x\n",
    "        return out\n",
    "\n",
    "class ResnetGenerator(nn.Module):\n",
    "    def __init__(self, input_ch):\n",
    "        super(ResnetGenerator, self).__init__()\n",
    "\n",
    "        self.init_layer = nn.Sequential(\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(input_ch, 16, kernel_size=7, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True))\n",
    "\n",
    "        self.donw_sampling_layer1 = nn.Sequential(\n",
    "            # down sampling\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self.donw_sampling_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True))\n",
    "\n",
    "        self.res_block = nn.Sequential(*[resnet_block(64) for i in range(3)])\n",
    "\n",
    "        self.up_samplig_layer1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1, bias=True),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self.up_samplig_layer2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1, bias=True),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(16, input_ch, kernel_size=7, padding=0),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.model(x)\n",
    "        out1 = self.init_layer(x)\n",
    "        out2 = self.donw_sampling_layer1(out1)\n",
    "        out3 = self.donw_sampling_layer2(out2)\n",
    "        out4 = self.res_block(out3)\n",
    "        out5 = self.up_samplig_layer1(out4)\n",
    "        out6 = self.up_samplig_layer2(out5)\n",
    "        out7 = self.output_layer(out6)\n",
    "        return out7\n",
    "\n",
    "    def set_requires_grad(self, mode):\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = mode\n",
    "\n",
    "class PatchGanDiscriminator(nn.Module):\n",
    "    def __init__(self, input_ch):\n",
    "        super(PatchGanDiscriminator, self).__init__()\n",
    "\n",
    "        model = [\n",
    "            nn.Conv2d(input_ch, 16, kernel_size=7, stride=1, padding=1, padding_mode='replicate'),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "\n",
    "            nn.Conv2d(16, 16, kernel_size=4, stride=2, padding=1, bias=True),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(p=0.2),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=4, stride=2, padding=1, bias=True),  # 1\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(p=0.2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1, bias=True),  # 2\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(p=0.2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(p=0.2),\n",
    "\n",
    "            nn.Conv2d(128, 1, kernel_size=4, stride=1, padding=1)\n",
    "        ]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def set_requires_grad(self, mode):\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = mode\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, gan_mode):\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.register_buffer('real_label', torch.tensor(1.0))\n",
    "        self.register_buffer('fake_label', torch.tensor(0.0))\n",
    "        self.gan_mode = gan_mode\n",
    "\n",
    "        if gan_mode == 'lsgan':\n",
    "            self.loss = nn.MSELoss()\n",
    "        elif gan_mode == 'wgan_gp':\n",
    "            self.loss = None\n",
    "\n",
    "    def __call__(self, prediction, target_is_real):\n",
    "        if self.gan_mode == 'lsgan':\n",
    "            if target_is_real:\n",
    "                target_tensor = self.real_label  # .to(self.device)\n",
    "            else:\n",
    "                target_tensor = self.fake_label  # .to(self.device)\n",
    "\n",
    "            target_tensor = target_tensor.expand_as(prediction)\n",
    "            loss = self.loss(prediction, target_tensor)\n",
    "        elif self.gan_mode == 'wgan_gp':\n",
    "            if target_is_real:\n",
    "                loss = -prediction.mean()\n",
    "            else:\n",
    "                loss = prediction.mean()\n",
    "        return loss\n",
    "\n",
    "def _gradient_penalty(netD, real_data, fake_data, type=\"mixed\", constant=1.0, lambda_gp=10.0):\n",
    "    if lambda_gp > 0.0:\n",
    "        if type == 'real':  # either use real images, fake images, or a linear interpolation of two.\n",
    "            interpolatesv = real_data\n",
    "        elif type == 'fake':\n",
    "            interpolatesv = fake_data\n",
    "        elif type == 'mixed':\n",
    "            alpha = torch.rand(real_data.shape[0], 1, device=real_data.device)\n",
    "            alpha = alpha.expand(real_data.shape[0], real_data.nelement() // real_data.shape[0]).contiguous().view(\n",
    "                *real_data.shape)\n",
    "            interpolatesv = alpha * real_data + ((1 - alpha) * fake_data)\n",
    "        else:\n",
    "            raise NotImplementedError('{} not implemented'.format(type))\n",
    "        interpolatesv.requires_grad_(True)\n",
    "        disc_interpolates = netD(interpolatesv)\n",
    "        gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=interpolatesv,\n",
    "                                        grad_outputs=torch.ones(disc_interpolates.size()).to(real_data.device),\n",
    "                                        create_graph=True, retain_graph=True, only_inputs=True)\n",
    "        gradients = gradients[0].view(real_data.size(0), -1)  # flat the data\n",
    "        gradient_penalty = (((gradients + 1e-16).norm(2, dim=1) - constant) ** 2).mean() * lambda_gp  # added eps\n",
    "        return gradient_penalty, gradients\n",
    "    else:\n",
    "        return 0.0, None\n",
    "\n",
    "class cycleGAN_model(nn.Module):\n",
    "    def __init__(self, input_ch=3,\n",
    "                 optim_lr=0.0002,\n",
    "                 gan_mode='lsgan',\n",
    "                 guided=False):\n",
    "        import itertools\n",
    "\n",
    "        super(cycleGAN_model, self).__init__()\n",
    "        self.gan_mode = gan_mode\n",
    "        self.guided = guided\n",
    "\n",
    "        self.Gen = nn.ModuleDict({\n",
    "            'A': ResnetGenerator(input_ch),\n",
    "            'B': ResnetGenerator(input_ch)\n",
    "        })\n",
    "\n",
    "        # wandb.watch(self.Gen['A'], log='all')\n",
    "        # wandb.watch(self.Gen['B'], log='all')\n",
    "\n",
    "        self.Dis = nn.ModuleDict({\n",
    "            'A': PatchGanDiscriminator(input_ch),\n",
    "            'B': PatchGanDiscriminator(input_ch)\n",
    "        })\n",
    "\n",
    "        # wandb.watch(self.Dis['A'], log='all')\n",
    "        # wandb.watch(self.Dis['B'], log='all')\n",
    "\n",
    "        self.optimizer = {\n",
    "            'G': torch.optim.Adam(itertools.chain(self.Gen['A'].parameters(), self.Gen['B'].parameters()), lr=optim_lr,\n",
    "                                  betas=(0.5, 0.999)),\n",
    "            'D_A': torch.optim.Adam(self.Dis['A'].parameters(), lr=optim_lr,\n",
    "                                  betas=(0.5, 0.999)),\n",
    "            'D_B': torch.optim.Adam(self.Dis['B'].parameters(), lr=optim_lr,\n",
    "                                  betas=(0.5, 0.999))\n",
    "        }\n",
    "\n",
    "        self.schedular = {\n",
    "            'G': torch.optim.lr_scheduler.LambdaLR(self.optimizer['G'], lr_lambda=lambda epoch: 0.95 ** epoch),\n",
    "            'D_A': torch.optim.lr_scheduler.LambdaLR(self.optimizer['D_A'], lr_lambda=lambda epoch: 0.95 ** epoch),\n",
    "            'D_B': torch.optim.lr_scheduler.LambdaLR(self.optimizer['D_B'], lr_lambda=lambda epoch: 0.95 ** epoch)\n",
    "        }\n",
    "\n",
    "        self.criterion = nn.ModuleDict({\n",
    "            'cycle': nn.L1Loss(),\n",
    "            'idt': nn.L1Loss(),\n",
    "            'gan': GANLoss(self.gan_mode),\n",
    "            'mse': nn.MSELoss(),\n",
    "            'guided': nn.L1Loss()\n",
    "        })\n",
    "\n",
    "        self.lambda_idt = 0.5\n",
    "        self.lambda_A = 10.0\n",
    "        self.lambda_B = 10.0\n",
    "\n",
    "    def forward(self, data_A, data_B, mode: str):\n",
    "        if mode == 'gen':\n",
    "            A_out = self.Gen['A'](data_A)\n",
    "            B_out = self.Gen['B'](data_B)\n",
    "        elif mode == 'dis':\n",
    "            A_out = self.Dis['A'](data_A)\n",
    "            B_out = self.Dis['B'](data_B)\n",
    "        else:\n",
    "            raise None\n",
    "        return A_out, B_out\n",
    "\n",
    "    def model_train_discriminator(self, real_A, real_B):\n",
    "        self.train()\n",
    "\n",
    "        fake_B, fake_A = self(real_A, real_B, 'gen')\n",
    "\n",
    "        self.set_requires_grad('dis', True)\n",
    "\n",
    "        self.optimizer['D_B'].zero_grad()\n",
    "\n",
    "        pred_real_B, pred_real_A = self(real_B, real_A, 'dis')  # netA netB\n",
    "        pred_fake_B, pred_fake_A = self(fake_B.detach(), fake_A.detach(), 'dis')\n",
    "\n",
    "        # Discriminator B update\n",
    "        loss_D_B_Real = self.criterion['gan'](pred_real_A, True)\n",
    "        loss_D_B_fake = self.criterion['gan'](pred_fake_A, False)\n",
    "\n",
    "        if self.gan_mode == 'lsgan':\n",
    "            loss_D_B = (loss_D_B_fake + loss_D_B_Real) * 0.5\n",
    "        elif self.gan_mode == 'wgan_gp':\n",
    "            gradient_penalty_B = _gradient_penalty(self.Dis['B'], real_A, fake_A.detach())\n",
    "            loss_D_B = loss_D_B_fake + loss_D_B_Real + gradient_penalty_B[0]\n",
    "\n",
    "        loss_D_B.backward()\n",
    "        self.optimizer['D_B'].step()\n",
    "\n",
    "        # Discriminator A update\n",
    "        self.optimizer['D_A'].zero_grad()\n",
    "\n",
    "        loss_D_A_Real = self.criterion['gan'](pred_real_B, True)\n",
    "        loss_D_A_fake = self.criterion['gan'](pred_fake_B, False)\n",
    "\n",
    "        if self.gan_mode == 'lsgan':\n",
    "            loss_D_A = (loss_D_A_Real + loss_D_A_fake) * 0.5\n",
    "        elif self.gan_mode == 'wgan_gp':\n",
    "            gradient_penalty_A = _gradient_penalty(self.Dis['A'], real_B, fake_B.detach())\n",
    "            loss_D_A = loss_D_A_Real + loss_D_A_fake + gradient_penalty_A[0]\n",
    "\n",
    "        loss_D_A.backward()\n",
    "        self.optimizer['D_A'].step()\n",
    "\n",
    "        loss_dic = {'dis_a': loss_D_A.item(),\n",
    "                    'dis_b': loss_D_B.item()}\n",
    "\n",
    "        return loss_dic\n",
    "\n",
    "    def model_train_generator(self, real_A, real_B):\n",
    "        self.train()\n",
    "\n",
    "        fake_B, fake_A = self(real_A, real_B, 'gen')\n",
    "        rec_B, rec_A = self(fake_A, fake_B, 'gen')\n",
    "\n",
    "        self.set_requires_grad('dis', False)\n",
    "        self.optimizer['G'].zero_grad()\n",
    "\n",
    "        idt_A, idt_B = self(real_B, real_A, 'gen')\n",
    "\n",
    "        loss_idt_A = self.criterion['idt'](idt_A, real_B) * self.lambda_B * self.lambda_idt\n",
    "        loss_idt_B = self.criterion['idt'](idt_B, real_A) * self.lambda_A * self.lambda_idt\n",
    "\n",
    "        dis_A_fake_B, dis_B_fake_A = self(fake_B, fake_A, 'dis')  # dis_A(fake_B) / dis_B(fake_A)\n",
    "\n",
    "        loss_G_A = self.criterion['gan'](dis_A_fake_B, True)\n",
    "        loss_G_B = self.criterion['gan'](dis_B_fake_A, True)\n",
    "\n",
    "        loss_cycle_A = self.criterion['cycle'](rec_A, real_A) * self.lambda_A\n",
    "        loss_cycle_B = self.criterion['cycle'](rec_B, real_B) * self.lambda_B\n",
    "\n",
    "        # Guied Loss (paired)\n",
    "        if self.guided:\n",
    "            loss_guided_A = self.criterion['guided'](fake_B, real_B)\n",
    "            loss_guided_B = self.criterion['guided'](fake_A, real_A)\n",
    "        else:\n",
    "            loss_guided_A = 0\n",
    "            loss_guided_B = 0\n",
    "        ##########\n",
    "\n",
    "        loss_Gen = loss_G_A + loss_G_B + loss_cycle_A + loss_cycle_B + loss_idt_A + loss_idt_B + loss_guided_A + loss_guided_B\n",
    "        loss_Gen.backward()\n",
    "\n",
    "        self.optimizer['G'].step()\n",
    "\n",
    "        loss_dic = {'gen': loss_Gen.item()}\n",
    "\n",
    "        inference_image = {\n",
    "            'real_a': real_A,\n",
    "            'real_b': real_B,\n",
    "            'atob_fake': fake_B,\n",
    "            'btoa_fake': fake_A,\n",
    "            'rec_a': rec_A,\n",
    "            'rec_b': rec_B\n",
    "        }\n",
    "\n",
    "        return loss_dic, {key: self.tensortonp(inference_image[key]) for key in inference_image}\n",
    "\n",
    "    def model_valid(self, real_A, real_B):\n",
    "        self.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            fake_B, fake_A = self(real_A, real_B, 'gen')\n",
    "\n",
    "            true = (real_B * 255).type(torch.uint8).float()\n",
    "            fake_true = (fake_B * 255).type(torch.uint8).float()\n",
    "            rmse_loss = torch.sqrt(self.criterion['mse'](fake_true, true))\n",
    "\n",
    "        img_dict = {\n",
    "            'real_A': real_A,\n",
    "            'fake_B': fake_B,\n",
    "\n",
    "            'real_B': real_B,\n",
    "            'fake_A': fake_A,\n",
    "        }\n",
    "\n",
    "        return rmse_loss.item(), {key: self.tensortonp(img_dict[key]) for key in img_dict}\n",
    "\n",
    "    def tensortonp(self, tensor):\n",
    "        return (tensor.detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "\n",
    "    def set_requires_grad(self, net_type='dis', mode=True):\n",
    "        if net_type == 'gen':\n",
    "            net_dic = self.Gen\n",
    "        elif net_type == 'dis':\n",
    "            net_dic = self.Dis\n",
    "\n",
    "        for key in net_dic:\n",
    "            net_dic[key].set_requires_grad(mode)\n",
    "\n",
    "    def schedular_step(self):\n",
    "        self.schedular['G'].step()\n",
    "        self.schedular['D_A'].step()\n",
    "        self.schedular['D_B'].step()\n",
    "\n",
    "    def model_save(self, PATH):\n",
    "        temp_dict = {}\n",
    "        key_list = [key for key in self.__dict__.keys() if not '_' in key[0]]\n",
    "        key_list.extend([key for key in self.__dict__['_modules'].keys()])\n",
    "\n",
    "        for key in key_list:\n",
    "            if hasattr(self, key):\n",
    "                value = getattr(self, key)\n",
    "                if isinstance(value, dict):\n",
    "                    if not key in temp_dict:\n",
    "                        temp_dict[key] = {}\n",
    "                    for sub_key in value.keys():\n",
    "                        if not sub_key in temp_dict[key]:\n",
    "                            temp_dict[key][sub_key] = value[sub_key].state_dict()\n",
    "                elif isinstance(value, nn.ModuleDict):\n",
    "                    if not key in temp_dict:\n",
    "                        temp_dict[key] = value.state_dict()\n",
    "                else:\n",
    "                    if not key in temp_dict:\n",
    "                        temp_dict[key] = value\n",
    "\n",
    "        torch.save(temp_dict, PATH)\n",
    "\n",
    "    def model_load(self, PATH, device):\n",
    "        state_dict = torch.load(PATH, map_location=device)\n",
    "\n",
    "        for cls_key in state_dict.keys():\n",
    "            if hasattr(self, cls_key):\n",
    "                value = getattr(self, cls_key)\n",
    "                if isinstance(value, dict):\n",
    "                    for sub_key in value.keys():\n",
    "                        value[sub_key].load_state_dict(state_dict[cls_key][sub_key])\n",
    "                elif isinstance(value, nn.ModuleDict):\n",
    "                    value.load_state_dict(state_dict[cls_key])\n",
    "                else:\n",
    "                    setattr(self, cls_key, state_dict[cls_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac8f2ce",
   "metadata": {},
   "source": [
    "# Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9f2c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_list(abs_path):\n",
    "    # abs_path = '/home/kji/workspace/jupyter_kji/samsumg_sem_dataset'\n",
    "\n",
    "    # Dataset path\n",
    "    sim_depth_path = os.path.join(abs_path, 'simulation_data/Depth')\n",
    "    sim_sem_path = os.path.join(abs_path, 'simulation_data/SEM')\n",
    "\n",
    "    train_path = os.path.join(abs_path, 'train')\n",
    "\n",
    "    # only Test\n",
    "    test_path = os.path.join(abs_path, 'test/SEM')\n",
    "\n",
    "    sim_depth_img_path_dic = dict()\n",
    "    for case in os.listdir(sim_depth_path):\n",
    "        if not case in sim_depth_img_path_dic:\n",
    "            sim_depth_img_path_dic[case] = []\n",
    "        for folder in os.listdir(os.path.join(sim_depth_path, case)):\n",
    "            img_list = glob.glob(os.path.join(sim_depth_path, case, folder, '*.png'))\n",
    "            for img in img_list:\n",
    "                sim_depth_img_path_dic[case].append(img)\n",
    "                sim_depth_img_path_dic[case].append(img)\n",
    "\n",
    "    sim_sem_img_path_dic = dict()\n",
    "    for case in os.listdir(sim_sem_path):\n",
    "        if not case in sim_sem_img_path_dic:\n",
    "            sim_sem_img_path_dic[case] = []\n",
    "        for folder in os.listdir(os.path.join(sim_sem_path, case)):\n",
    "            img_list = glob.glob(os.path.join(sim_sem_path, case, folder, '*.png'))\n",
    "            sim_sem_img_path_dic[case].extend(img_list)\n",
    "\n",
    "    train_avg_depth = dict()\n",
    "    with open(os.path.join(train_path, \"average_depth.csv\"), 'r') as csvfile:\n",
    "        temp = csv.reader(csvfile)\n",
    "        for idx, line in enumerate(temp):\n",
    "            if idx > 0:\n",
    "                depth_key, site_key = line[0].split('_site')\n",
    "                depth_key = depth_key.replace(\"d\", \"D\")\n",
    "                site_key = \"site\" + site_key\n",
    "                if not depth_key in train_avg_depth:\n",
    "                    train_avg_depth[depth_key] = dict()\n",
    "\n",
    "                train_avg_depth[depth_key][site_key] = float(line[1])\n",
    "\n",
    "    train_img_path_dic = dict()\n",
    "    for depth in os.listdir(os.path.join(train_path, \"SEM\")):\n",
    "        if not depth in train_img_path_dic:\n",
    "            train_img_path_dic[depth] = []\n",
    "        for site in os.listdir(os.path.join(train_path, \"SEM\", depth)):\n",
    "            img_list = glob.glob(os.path.join(train_path, \"SEM\", depth, site, \"*.png\"))\n",
    "            train_img_path_dic[depth].extend([[temp_img, train_avg_depth[depth][site]] for temp_img in img_list])\n",
    "\n",
    "    test_img_path_list = glob.glob(os.path.join(test_path, \"*.png\"))\n",
    "\n",
    "    result_dic = dict()\n",
    "    result_dic['sim'] = dict()\n",
    "    result_dic['sim']['sem'] = sim_sem_img_path_dic\n",
    "    result_dic['sim']['depth'] = sim_depth_img_path_dic\n",
    "    result_dic['train'] = train_img_path_dic\n",
    "    result_dic['test'] = np.array(test_img_path_list)\n",
    "    result_dic['train_avg_depth'] = train_avg_depth\n",
    "\n",
    "    return result_dic\n",
    "\n",
    "result_dic = get_img_list(cfg['db_path'])\n",
    "\n",
    "'''\n",
    "train sem ->  sim sem -> sim depth\n",
    "\n",
    "case 별로 dataset을 나눠야됨.\n",
    "'''\n",
    "\n",
    "class gan_dataset(Dataset):\n",
    "    def __init__(self, a_data_path, b_data_path, transform=None):\n",
    "        super(gan_dataset, self).__init__()\n",
    "        self.a_data_path = a_data_path\n",
    "        self.b_data_path = b_data_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.a_size = len(a_data_path)\n",
    "        self.b_size = len(b_data_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.a_size > self.b_size:\n",
    "            a_idx = idx\n",
    "            b_idx = idx % self.b_size\n",
    "        else:\n",
    "            a_idx = idx % self.a_size\n",
    "            b_idx = idx\n",
    "        if isinstance(self.a_data_path[a_idx], str):\n",
    "            a_path = self.a_data_path[a_idx]\n",
    "        elif isinstance(self.a_data_path[a_idx], list):\n",
    "            a_path = self.a_data_path[a_idx][0]\n",
    "\n",
    "        if isinstance(self.b_data_path[b_idx], str):\n",
    "            b_path = self.b_data_path[b_idx]\n",
    "        elif isinstance(self.b_data_path[b_idx], list):\n",
    "            b_path = self.b_data_path[b_idx][0]\n",
    "\n",
    "        a_img = PIL.Image.open(a_path).convert(\"L\")\n",
    "        b_img = PIL.Image.open(b_path).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            a_img = self.transform(a_img)\n",
    "            b_img = self.transform(b_img)\n",
    "\n",
    "        a_img = (np.array(a_img) / 255.)\n",
    "        a_img = a_img.reshape(1, *a_img.shape).astype(np.float32)\n",
    "        b_img = (np.array(b_img) / 255.)\n",
    "        b_img = b_img.reshape(1, *b_img.shape).astype(np.float32)\n",
    "\n",
    "        return a_img, b_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.a_data_path), len(self.b_data_path))\n",
    "\n",
    "def create_dataloader(a_key, b_key, t_ratio, result_dic, case=1):\n",
    "    if 'sim' in a_key:\n",
    "        a_list = result_dic['sim'][a_key.split('_')[-1]][f\"Case_{case}\"]\n",
    "    else:\n",
    "        a_list = result_dic['train'][f\"Depth_{100 + 10 * case}\"]\n",
    "    if 'sim' in b_key:\n",
    "        b_list = result_dic['sim'][b_key.split('_')[-1]][f\"Case_{case}\"]\n",
    "    else:\n",
    "        b_list = result_dic['train'][f\"Depth_{100 + 10 * case}\"]\n",
    "\n",
    "    horizon_transform = transforms.RandomHorizontalFlip(1.0)\n",
    "    rotate_transform = transforms.RandomRotation((180, 180))\n",
    "    vertical_transform = transforms.RandomVerticalFlip(1.0)\n",
    "\n",
    "    a_train_data_size = int(len(a_list) * t_ratio)\n",
    "    b_train_data_size = int(len(b_list) * t_ratio)\n",
    "\n",
    "    train_dataset = gan_dataset(a_list[:a_train_data_size], b_list[:b_train_data_size], None) + \\\n",
    "                    gan_dataset(a_list[:a_train_data_size], b_list[:b_train_data_size], horizon_transform) + \\\n",
    "                    gan_dataset(a_list[:a_train_data_size], b_list[:b_train_data_size], rotate_transform) + \\\n",
    "                    gan_dataset(a_list[:a_train_data_size], b_list[:b_train_data_size], vertical_transform)\n",
    "\n",
    "    valid_dataset = gan_dataset(a_list[a_train_data_size:], b_list[b_train_data_size:], None) + \\\n",
    "                    gan_dataset(a_list[a_train_data_size:], b_list[b_train_data_size:], horizon_transform) + \\\n",
    "                    gan_dataset(a_list[a_train_data_size:], b_list[b_train_data_size:], rotate_transform) + \\\n",
    "                    gan_dataset(a_list[a_train_data_size:], b_list[b_train_data_size:], vertical_transform)\n",
    "\n",
    "    return DataLoader(train_dataset, batch_size=cfg['batch_size'], num_workers=cfg['num_workers'], shuffle=True), \\\n",
    "           DataLoader(valid_dataset, batch_size=cfg['batch_size'], num_workers=cfg['num_workers'], shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cb4a18",
   "metadata": {},
   "source": [
    "# Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac7389b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def valid(model, valid_dataloader, device):\n",
    "    rmse_list = []\n",
    "    img_mean_list = []\n",
    "    for step_i, data_tuple in enumerate(valid_dataloader):\n",
    "        real_a = data_tuple[0].to(device, non_blocking=True)\n",
    "        real_b = data_tuple[1].to(device, non_blocking=True)\n",
    "\n",
    "        rmse_loss, img_dict = model.model_valid(real_a, real_b)\n",
    "        rmse_list.append(rmse_loss)\n",
    "        if step_i == 0:\n",
    "            img_list = [img_dict[key][0][0] for key in img_dict]\n",
    "            img_list = [wandb.Image(PIL.Image.fromarray(np.concatenate((img_list[i], img_list[i+1]), axis=-1)).convert('L'), caption=key)\n",
    "                        for i, key in enumerate(img_dict.keys()) if i % 2 == 0]\n",
    "            wandb.log({\n",
    "                \"example image\": img_list\n",
    "            })\n",
    "        \n",
    "    \n",
    "        img_mean_list.extend(list(np.mean(img_dict['fake_B'], axis=(1,2,3))))\n",
    "        \n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    \n",
    "    plt.hist(img_mean_list, bins=100, density=True, alpha=0.5, color=plt.cm.tab20c(1))\n",
    "    plt.xlim(80, 200)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    wandb.log({\n",
    "        'plot': wandb.Image(fig)\n",
    "    })\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.cla()\n",
    "    plt.close()\n",
    "    \n",
    "    return np.mean(rmse_list)\n",
    "\n",
    "def training(case, epochs, device, type, guided ,checkpoint_path=None):\n",
    "    best_rmse_loss = 9999\n",
    "    critic_iter = 5\n",
    "    best_epoch = 0\n",
    "\n",
    "    if type == 'semtodepth':\n",
    "        a_key = 'sim_sem'\n",
    "        b_key = 'sim_depth'\n",
    "    elif type == 'simtotrain':\n",
    "        a_key = 'sim_sem'\n",
    "        b_key = 'train'\n",
    "\n",
    "    train_dataloader, valid_dataloader = create_dataloader(a_key=a_key,\n",
    "                                                           b_key=b_key,\n",
    "                                                           t_ratio=0.8,\n",
    "                                                           result_dic=result_dic,\n",
    "                                                           case=case)\n",
    "\n",
    "    model = cycleGAN_model(1, optim_lr=0.0002, gan_mode='wgan_gp', guided=guided)\n",
    "\n",
    "    if checkpoint_path:\n",
    "        model.model_load(checkpoint_path, device)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loss_list = [[], [], []]\n",
    "        for step_i, data_tuple in enumerate(train_dataloader):\n",
    "            real_a = data_tuple[0].to(device, non_blocking=True)\n",
    "            real_b = data_tuple[1].to(device, non_blocking=True)\n",
    "\n",
    "            dis_loss = model.model_train_discriminator(real_a, real_b)\n",
    "            loss_list[1].append(dis_loss['dis_a'])\n",
    "            loss_list[2].append(dis_loss['dis_b'])\n",
    "            if step_i % critic_iter == 0:\n",
    "                gen_loss, img_dic = model.model_train_generator(real_a, real_b)\n",
    "                loss_list[0].append(gen_loss['gen'])\n",
    "\n",
    "                wandb.log({\n",
    "                    'Gen_step_loss': gen_loss,\n",
    "                    'Dis_A_step_loss': dis_loss['dis_a'],\n",
    "                    'Dis_B_step_loss': dis_loss['dis_b']\n",
    "                })\n",
    "\n",
    "            \n",
    "        rmse_loss = valid(model, valid_dataloader, device)\n",
    "        print(f'epoch - {epoch}, gen loss - {gen_loss}, rmse loss - {rmse_loss}')\n",
    "        wandb.log({\n",
    "            'Gen_loss': np.mean(loss_list[0]),\n",
    "            'Dis_A_loss': np.mean(loss_list[1]),\n",
    "            'Dis_B_loss': np.mean(loss_list[2]),\n",
    "            'learning_rate': model.schedular['G'].get_last_lr(),\n",
    "            'rmse_loss': rmse_loss\n",
    "        })\n",
    "\n",
    "        if best_rmse_loss > rmse_loss:\n",
    "            best_rmse_loss = rmse_loss\n",
    "            model.model_save(f'./case{case}_t({type})_best_model.pth')\n",
    "\n",
    "        model.schedular_step()\n",
    "    print(f'training end, best epoch - {best_epoch}, best valid rmse loss - {best_rmse_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8282a077",
   "metadata": {},
   "source": [
    "# Simulation Sem to Simulation Depth Case #1 training \n",
    "## Add Guided L1 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a235cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=project_name, entity=\"kimjiil2013\", name=\"semtodepth_c1\")\n",
    "training(1, cfg['epochs'], cfg['device'], 'semtodepth', True)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263190d9",
   "metadata": {},
   "source": [
    "# Simulation Sem to Simulation Depth Case #2 training \n",
    "## Add Guided L1 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e009ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=project_name, entity=\"kimjiil2013\", name=\"semtodepth_c2\")\n",
    "training(2, cfg['epochs'], cfg['device'], 'semtodepth', True)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8283be3",
   "metadata": {},
   "source": [
    "# Simulation Sem to Simulation Depth Case #3 training \n",
    "## Add Guided L1 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703e533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=project_name, entity=\"kimjiil2013\", name=\"semtodepth_c3\")\n",
    "training(3, cfg['epochs'], cfg['device'], 'semtodepth', True)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc78f21a",
   "metadata": {},
   "source": [
    "# Simulation Sem to Simulation Depth Case #4 training \n",
    "## Add Guided L1 Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f153cab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=project_name, entity=\"kimjiil2013\", name=\"semtodepth_c4\")\n",
    "training(4, cfg['epochs'], cfg['device'], 'semtodepth', True)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8d8bb2",
   "metadata": {},
   "source": [
    "# Simulation Sem to Train Sem Case #1 training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692a01d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=project_name, entity=\"kimjiil2013\", name=\"simtotrain_c1\")\n",
    "training(1, cfg['epochs'], cfg['device'], 'simtotrain', False)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad99cd5c",
   "metadata": {},
   "source": [
    "# Simulation Sem to Train Sem Case #2 training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632d4a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"Samsung sem CycleGan\", entity=\"kimjiil2013\", name=\"simtotrain_c2\")\n",
    "training(2, cfg['epochs'], cfg['device'], 'simtotrain', False)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bc1a1a",
   "metadata": {},
   "source": [
    "# Simulation Sem to Train Sem Case #3 training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c277efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"Samsung sem CycleGan\", entity=\"kimjiil2013\", name=\"simtotrain_c3\")\n",
    "training(3, cfg['epochs'], cfg['device'], 'simtotrain', False)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e1cb94",
   "metadata": {},
   "source": [
    "# Simulation Sem to Train Sem Case #4 training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc5d356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkimjiil2013\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.7 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/kji/workspace/jupyter_kji/wandb/run-20221227_161106-2sh76znc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kimjiil2013/221227_Samsung_sem/runs/2sh76znc\" target=\"_blank\">simtotrain_c4</a></strong> to <a href=\"https://wandb.ai/kimjiil2013/221227_Samsung_sem\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch - 0, gen loss - {'gen': 0.6394338607788086}, rmse loss - 14.568509172249545\n",
      "epoch - 1, gen loss - {'gen': 0.570279598236084}, rmse loss - 14.762874283033984\n",
      "epoch - 2, gen loss - {'gen': 0.5614814758300781}, rmse loss - 14.92353095339673\n",
      "epoch - 3, gen loss - {'gen': 0.5641460418701172}, rmse loss - 14.836537565252438\n",
      "epoch - 4, gen loss - {'gen': 0.5018516778945923}, rmse loss - 15.050771956074282\n",
      "epoch - 5, gen loss - {'gen': 0.6536893844604492}, rmse loss - 14.852180676266716\n",
      "epoch - 6, gen loss - {'gen': 0.6067661046981812}, rmse loss - 14.672394043405118\n",
      "epoch - 7, gen loss - {'gen': 0.41985756158828735}, rmse loss - 14.858069326604864\n",
      "epoch - 8, gen loss - {'gen': 0.14360401034355164}, rmse loss - 14.804652662734703\n",
      "epoch - 9, gen loss - {'gen': 0.15292397141456604}, rmse loss - 14.822184381449794\n",
      "epoch - 10, gen loss - {'gen': 0.3205029368400574}, rmse loss - 14.711959705141638\n",
      "epoch - 11, gen loss - {'gen': 0.2846326231956482}, rmse loss - 14.691237972231368\n",
      "epoch - 12, gen loss - {'gen': 0.28453487157821655}, rmse loss - 14.79633204083601\n",
      "epoch - 13, gen loss - {'gen': 0.23402880132198334}, rmse loss - 14.843314501632184\n",
      "epoch - 14, gen loss - {'gen': 0.29084089398384094}, rmse loss - 14.822086314873502\n",
      "epoch - 15, gen loss - {'gen': 0.29448628425598145}, rmse loss - 14.766311455476767\n",
      "epoch - 16, gen loss - {'gen': 0.16769173741340637}, rmse loss - 14.911818949498814\n",
      "epoch - 17, gen loss - {'gen': 0.08667121827602386}, rmse loss - 15.010851092884021\n",
      "epoch - 18, gen loss - {'gen': 0.20765700936317444}, rmse loss - 15.002025428293376\n",
      "epoch - 19, gen loss - {'gen': 0.16941925883293152}, rmse loss - 15.27291626595923\n",
      "epoch - 20, gen loss - {'gen': 0.2804291844367981}, rmse loss - 15.28418506115565\n",
      "epoch - 21, gen loss - {'gen': 0.11359281092882156}, rmse loss - 15.322827983166459\n",
      "epoch - 22, gen loss - {'gen': 0.19902628660202026}, rmse loss - 15.202937416484875\n",
      "epoch - 23, gen loss - {'gen': 0.018669486045837402}, rmse loss - 15.56582524767661\n",
      "epoch - 24, gen loss - {'gen': 0.028720282018184662}, rmse loss - 15.321157429051135\n",
      "epoch - 25, gen loss - {'gen': -0.13253355026245117}, rmse loss - 15.32858408157236\n",
      "epoch - 26, gen loss - {'gen': 0.08136427402496338}, rmse loss - 15.163815491313864\n",
      "epoch - 27, gen loss - {'gen': -0.04150404781103134}, rmse loss - 15.212912209359482\n",
      "epoch - 28, gen loss - {'gen': 0.08845679461956024}, rmse loss - 15.238894107157014\n",
      "epoch - 29, gen loss - {'gen': -0.04024747014045715}, rmse loss - 15.230563985465638\n",
      "epoch - 30, gen loss - {'gen': 0.017053302377462387}, rmse loss - 15.068936947966854\n",
      "epoch - 31, gen loss - {'gen': 0.014555417001247406}, rmse loss - 15.319455296351022\n",
      "epoch - 32, gen loss - {'gen': -0.04082242399454117}, rmse loss - 15.321170410986756\n",
      "epoch - 33, gen loss - {'gen': -0.07067909836769104}, rmse loss - 15.188639192123695\n",
      "epoch - 34, gen loss - {'gen': -0.010074354708194733}, rmse loss - 15.169141227468794\n",
      "epoch - 35, gen loss - {'gen': 0.15280640125274658}, rmse loss - 15.19857204444294\n",
      "epoch - 36, gen loss - {'gen': 0.12436835467815399}, rmse loss - 15.454521480081706\n",
      "epoch - 37, gen loss - {'gen': 0.050722524523735046}, rmse loss - 15.269707813474085\n",
      "epoch - 38, gen loss - {'gen': 0.04426245391368866}, rmse loss - 15.192414179939185\n",
      "epoch - 39, gen loss - {'gen': 0.1066029742360115}, rmse loss - 15.371374336115988\n",
      "epoch - 40, gen loss - {'gen': 0.11685530841350555}, rmse loss - 15.33228994559538\n",
      "epoch - 41, gen loss - {'gen': 0.06325015425682068}, rmse loss - 15.370662664575331\n",
      "epoch - 42, gen loss - {'gen': 0.1091991662979126}, rmse loss - 15.22463696997104\n",
      "epoch - 43, gen loss - {'gen': 0.04514692723751068}, rmse loss - 15.324270989182251\n",
      "epoch - 44, gen loss - {'gen': 0.09415145218372345}, rmse loss - 15.210103860200551\n",
      "epoch - 45, gen loss - {'gen': 0.06782656162977219}, rmse loss - 15.283010194222426\n",
      "epoch - 46, gen loss - {'gen': 0.04395631328225136}, rmse loss - 15.282840100601591\n",
      "epoch - 47, gen loss - {'gen': 0.054944925010204315}, rmse loss - 15.290226711118354\n",
      "epoch - 48, gen loss - {'gen': 0.04012615978717804}, rmse loss - 15.299533680356296\n",
      "epoch - 49, gen loss - {'gen': 0.06638198345899582}, rmse loss - 15.235400678486842\n",
      "training end, best epoch - 0, best valid rmse loss - 14.568509172249545\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Dis_A_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Dis_A_step_loss</td><td>█▆▆▃▆▄▆▁▃▄▂▂▆▆▅▃▃▃▃▆▃▃▇▅▄▁▄▃▄▅▆▅▄▂▄▃▄▄▅▅</td></tr><tr><td>Dis_B_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Dis_B_step_loss</td><td>██▆▅▃▁▃▆▆▅▅▄▇▆█▄▂▅▅▆▄▅▄▅▆▄▆▆▇▆▅▅▆▅▆▆▆▆▄▄</td></tr><tr><td>Gen_loss</td><td>█▅▄▄▄▅▄▃▂▃▃▂▃▃▂▂▂▂▂▂▁▁▂▂▁▂▁▁▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>rmse_loss</td><td>▁▂▃▃▃▂▃▃▂▂▃▃▂▃▄▄▆▆▅█▆▅▆▆▅▆▆▅▅▇▆▅▆▇▆▆▆▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Dis_A_loss</td><td>-0.01058</td></tr><tr><td>Dis_A_step_loss</td><td>-0.02343</td></tr><tr><td>Dis_B_loss</td><td>-0.00822</td></tr><tr><td>Dis_B_step_loss</td><td>-0.00601</td></tr><tr><td>Gen_loss</td><td>0.05908</td></tr><tr><td>rmse_loss</td><td>15.2354</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">simtotrain_c4</strong>: <a href=\"https://wandb.ai/kimjiil2013/221227_Samsung_sem/runs/2sh76znc\" target=\"_blank\">https://wandb.ai/kimjiil2013/221227_Samsung_sem/runs/2sh76znc</a><br/>Synced 6 W&B file(s), 150 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221227_161106-2sh76znc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=project_name, entity=\"kimjiil2013\", name=\"simtotrain_c4\")\n",
    "training(4, cfg['epochs'], cfg['device'], 'simtotrain', False)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aa8718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
